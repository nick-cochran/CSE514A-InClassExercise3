CSE514 Ð Fall 2024 Programming Assignment 2This assignment is to give you hands-on experience with dimension reduction and the comparison  of different classification models. It consists of a programming assignment and a report. This project can be done in groups up to three, or as individuals. TopicCompare, analyze, and select a classification model for a series of binary classification problem.Programming workA) Data preprocessingYour dataset might contain response labels of two classes, multiple classes, or a numerical data type. This project requires three binary classification problems. Here are some options: 1. Dataset has two classes: Find a feature to split the dataset up into 3 populations2. Dataset has multiple classes: Pick 3 different pairs3. Dataset has numerical response values: Bin the values into classes. Once the variable has been processed to be categorical, refer to option 1 or option 2.B) Model fittingFor this project, you must pick 2*(size of group) from the following classification models:1. k-nearest neighbors	2.  Artificial Neural Network		3.  Decision tree4.   Random Forest		5.  Na•ve Bayes Classifier		6.  SVMFor each model, choose a hyperparameter to tune using 5-fold cross-validation. If the hyperparmeter is categorical (ex. which SVM kernel), you must test at least 3 options. If the hyperparameter is numerical (ex. # of neighbors in kNN) you must test at least 5 values. Hyperparameter tuning should be done separately for each classification problem.2. Dimension reductionFor each model, implement dimension reduction to reduce the number of features in half. Retrain your models using reduced datasets, including hyperparameter tuning.IMPORTANT: You may use any packages/libraries/code-bases as you like for the project, however, you will need to have control over certain aspects of the model that may be black-boxed by default. For example, a package that trains a kNN classifier and internally optimizes the k value is not ideal if you need the cross-validation results of testing different k values.Data to be usedYou may pick any dataset from the UCI repository at:  https://archive.ics.uci.edu/ml/datasets/You must find a dataset that has at least 10 features, and enough samples that each binary classification problem has at least 200 samples. For each binary classification problem, set aside 10% of relevant samples for final validation of the models. This means that you cannot use these samples to train your model parameters, your model hyperparameters, or your feature selection methods. 